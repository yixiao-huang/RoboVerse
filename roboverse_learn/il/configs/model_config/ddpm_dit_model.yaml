_target_: roboverse_learn.il.dp.policies.ddpm_dit_image_policy.DiffusionDiTImagePolicy

shape_meta: ${shape_meta}

noise_scheduler:
  _target_: diffusers.schedulers.scheduling_ddpm.DDPMScheduler
  num_train_timesteps: 100
  beta_start: 0.0001
  beta_end: 0.02
  beta_schedule: squaredcos_cap_v2
  variance_type: fixed_small # Yilun's paper uses fixed_small_log instead, but easy to cause Nan
  clip_sample: True # required when predict_epsilon=False
  prediction_type: epsilon # or sample

obs_encoder:
  _target_: roboverse_learn.il.dp.models.vision.multi_image_obs_encoder.MultiImageObsEncoder
  shape_meta: ${shape_meta}
  rgb_model:
    _target_: roboverse_learn.il.dp.models.vision.model_getter.get_resnet
    name: resnet18
    weights: null
  resize_shape: null
  crop_shape: null
  # constant center crop
  random_crop: True
  use_group_norm: True
  share_rgb_model: False
  imagenet_norm: True

horizon: ${horizon}
n_action_steps: ${eval:'${n_action_steps}+${n_latency_steps}'}
n_obs_steps: ${n_obs_steps}
num_inference_steps: 100
obs_as_global_cond: ${obs_as_global_cond}

diffusion_step_embed_dim: 128
hidden_dim: 512
num_layers: 4
num_heads: 8
mlp_ratio: 4
dropout: 0.1
