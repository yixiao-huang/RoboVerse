_target_: roboverse_learn.il.vita.policies.vita_policy.VITAImagePolicy


shape_meta: ${shape_meta}

obs_encoder:
  _target_: roboverse_learn.il.dp.models.vision.multi_image_obs_encoder.MultiImageObsEncoder
  shape_meta: ${shape_meta}
  rgb_model:
    _target_: roboverse_learn.il.dp.models.vision.model_getter.get_resnet
    name: resnet18
    weights: null
  resize_shape: null
  crop_shape: null
  # constant center crop
  random_crop: True
  use_group_norm: True
  share_rgb_model: False
  imagenet_norm: True

horizon: ${horizon}
n_action_steps: ${eval:'${n_action_steps}+${n_latency_steps}'}
n_obs_steps: ${n_obs_steps}

# VITA-specific parameters
decode_flow_latents: true
consistency_weight: 1.0
enc_contrastive_weight: 1e-4
flow_contrastive_weight: 0.0
latent_dim: 512

# Flow matcher parameters
flow_matcher:
  _target_: roboverse_learn.il.utils.flow_matchers.ExactOptimalTransportConditionalFlowMatcher
  sigma: 0.0
  num_sampling_steps: 6

# Flow network parameters
flow_net:
  hidden_dim: 512
  num_layers: 4
  mlp_ratio: 4
  dropout: 0.0

# Action autoencoder parameters
action_ae:
  kl_weight: 1e-6
  enc_recon_weight: 0.5
  flow_recon_weight: 0.5
  recon_loss_type: l1
  use_variational: false
  freeze_encoder: false
  freeze_decoder: false
  net:
    enc_hidden_dim: 512
    dec_hidden_dim: 512
    latent_dim: 512
    num_heads: 8
    mlp_ratio: 4
    dropout: 0.0
    num_layers: 4
