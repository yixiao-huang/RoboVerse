_target_: dp.models.ddim_unet_image_policy.DiffusionUnetImagePolicy

shape_meta: ${shape_meta}

noise_scheduler:
  _target_: diffusers.schedulers.scheduling_ddpm.DDPMScheduler
  num_train_timesteps: 100
  beta_start: 0.0001
  beta_end: 0.02
  beta_schedule: squaredcos_cap_v2
  variance_type: fixed_small # Yilun's paper uses fixed_small_log instead, but easy to cause Nan
  clip_sample: True # required when predict_epsilon=False
  prediction_type: epsilon # or sample

obs_encoder:
  _target_: diffusion_policy.model.vision.multi_image_obs_encoder.MultiImageObsEncoder
  shape_meta: ${shape_meta}
  rgb_model:
    _target_: diffusion_policy.model.vision.model_getter.get_resnet
    name: resnet18
    weights: null
  resize_shape: null
  crop_shape: null
  # constant center crop
  random_crop: True
  use_group_norm: True
  share_rgb_model: False
  imagenet_norm: True

horizon: ${horizon}
n_action_steps: ${eval:'${n_action_steps}+${n_latency_steps}'}
n_obs_steps: ${n_obs_steps}
num_inference_steps: 60
obs_as_global_cond: ${obs_as_global_cond}
# crop_shape: null
diffusion_step_embed_dim: 128
# down_dims: [512, 1024, 2048]
down_dims: [256, 512, 1024]
kernel_size: 5
n_groups: 8
cond_predict_scale: True
